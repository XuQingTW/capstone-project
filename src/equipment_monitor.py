import logging
from datetime import datetime  # datetime is used for GETDATE() in SQL queries and strftime
import pyodbc
from database import db

logger = logging.getLogger(__name__)


class EquipmentMonitor:
    """åŠå°é«”è¨­å‚™ç›£æ§èˆ‡ç•°å¸¸åµæ¸¬å™¨ (åƒ…é™åˆ‡å‰²æ©Ÿ)"""

    # è¨­å‚™é¡å‹å¸¸æ•¸ (åªä¿ç•™åˆ‡å‰²æ©Ÿ)
    DICER = "dicer"  # åˆ‡å‰²æ©Ÿ

    # åš´é‡ç¨‹åº¦å¸¸æ•¸
    SEVERITY_WARNING = "warning"  # è­¦å‘Š
    SEVERITY_CRITICAL = "critical"  # åš´é‡
    SEVERITY_EMERGENCY = "emergency"  # ç·Šæ€¥

    def __init__(self):
        self.db = db
        self.equipment_type_names = {
            self.DICER: "åˆ‡å‰²æ©Ÿ",
        }
        # é€™äº›æŒ‡æ¨™ç¾åœ¨æœƒå¾è³‡æ–™åº«çš„ equipment_metric_thresholds è¡¨ä¸­ç²å–æ¨™æº–
        self.equipment_metrics = {
            self.DICER: ["è®Šå½¢é‡(mm)", "è½‰é€Ÿ", "åˆ€å…·è£‚ç—•"],  # å¢åŠ åˆ€å…·è£‚ç—•
        }
        # ç”¨æ–¼å„²å­˜å¾è³‡æ–™åº«è¼‰å…¥çš„é–¾å€¼
        self.metric_thresholds_data = {}
        self._load_metric_thresholds_from_db()  # åˆå§‹åŒ–æ™‚å¾è³‡æ–™åº«è¼‰å…¥æ¨™æº–

    def _load_metric_thresholds_from_db(self):
        """å¾è³‡æ–™åº«çš„ equipment_metric_thresholds è¡¨ä¸­è¼‰å…¥æ‰€æœ‰æŒ‡æ¨™çš„é–¾å€¼ã€‚"""
        try:
            with self.db._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT
                        metric_type, normal_value,
                        warning_min, warning_max,
                        critical_min, critical_max,
                        emergency_min, emergency_max, emergency_op
                    FROM equipment_metric_thresholds;
                """)
                rows = cursor.fetchall()
                if not rows:
                    logger.warning("è³‡æ–™åº«ä¸­ equipment_metric_thresholds è¡¨ç„¡é–¾å€¼æ•¸æ“šã€‚")

                for row in rows:
                    (metric_type, normal_value,
                     w_min, w_max,
                     c_min, c_max,
                     e_min, e_max, e_op) = row

                    self.metric_thresholds_data[metric_type] = {
                        "normal_value": normal_value,
                        "warning": {"min": w_min, "max": w_max},
                        "critical": {"min": c_min, "max": c_max},
                        "emergency": {"min": e_min, "max": e_max, "op": e_op}
                    }
                logger.info(f"æˆåŠŸå¾è³‡æ–™åº«è¼‰å…¥ {len(self.metric_thresholds_data)} å€‹æŒ‡æ¨™çš„é–¾å€¼ã€‚")
        except pyodbc.Error as db_err:
            logger.exception(f"å¾è³‡æ–™åº«è¼‰å…¥é–¾å€¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {db_err}")
            self.metric_thresholds_data = {}  # æ¸…ç©ºï¼Œé¿å…ä½¿ç”¨ä¸å®Œæ•´çš„æ•¸æ“š
        except Exception as e:
            logger.exception(f"è¼‰å…¥é–¾å€¼æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e}")
            self.metric_thresholds_data = {}

    def check_all_equipment(self):
        """æª¢æŸ¥æ‰€æœ‰åˆ‡å‰²æ©Ÿè¨­å‚™æ˜¯å¦æœ‰ç•°å¸¸"""
        # åœ¨æ¯æ¬¡æª¢æŸ¥å‰é‡æ–°è¼‰å…¥é–¾å€¼ï¼Œä»¥ç¢ºä¿æ˜¯æœ€æ–°çš„ï¼ˆå¦‚æœè³‡æ–™åº«æœ‰æ›´æ–°ï¼‰
        self._load_metric_thresholds_from_db()

        try:
            with self.db._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    "SELECT equipment_id, name, eq_type FROM equipment "
                    "WHERE status <> 'offline' AND eq_type = ?;",
                    (self.DICER,)
                )
                equipments = cursor.fetchall()
                for equipment_id, name, eq_type in equipments:
                    self._check_equipment_metrics(
                        conn, equipment_id, name, eq_type
                    )
                logger.info("æ‰€æœ‰åˆ‡å‰²æ©Ÿè¨­å‚™æª¢æŸ¥å®Œæˆã€‚")
        except pyodbc.Error as db_err:
            logger.exception(f"æª¢æŸ¥æ‰€æœ‰åˆ‡å‰²æ©Ÿè¨­å‚™æ™‚ç™¼ç”Ÿè³‡æ–™åº«éŒ¯èª¤: {db_err}")
        except Exception as e:
            logger.exception(f"æª¢æŸ¥æ‰€æœ‰åˆ‡å‰²æ©Ÿè¨­å‚™æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e}")

    def _check_equipment_metrics(self, conn, equipment_id, name, eq_type):
        """æª¢æŸ¥è¨­å‚™çš„æŒ‡æ¨™æ˜¯å¦ç•°å¸¸"""
        try:
            cursor = conn.cursor()
            # SQL æŸ¥è©¢ä¿®æ”¹ï¼šåªé¸æ“‡å¯¦éš›æœƒç”¨åˆ°çš„æ¬„ä½ï¼Œç§»é™¤ threshold_min/max å› ç‚ºå®ƒå€‘å¾å¦ä¸€å¼µè¡¨ç²å–
            sql_get_metrics = """
                WITH RankedMetrics AS (
                    SELECT
                        id, equipment_id, metric_type, status, value, unit, timestamp,
                        ROW_NUMBER() OVER(
                            PARTITION BY equipment_id, metric_type
                            ORDER BY timestamp DESC
                        ) as rn
                    FROM equipment_metrics
                    WHERE equipment_id = ? AND timestamp > DATEADD(minute, -30, GETDATE())
                )
                SELECT id, equipment_id, metric_type, status, value, unit, timestamp
                FROM RankedMetrics
                WHERE rn = 1;
            """
            cursor.execute(sql_get_metrics, (equipment_id,))

            latest_metrics = {}
            for metric_row in cursor.fetchall():
                # è§£åŒ…éœ€è¦åŒ¹é…æ–°çš„ SELECT é †åº
                _id, _eq_id, metric_type, status, value, unit, ts = metric_row
                # é€™è£¡çš„ latest_metrics key ä½¿ç”¨ metric_type
                latest_metrics[metric_type] = {
                    "value": float(value) if value is not None else None,
                    "unit": unit,
                    "timestamp": ts,
                    "status_from_metric": status  # å„²å­˜æŒ‡æ¨™è‡ªèº«çš„ç‹€æ…‹
                }

            anomalies = []
            if not latest_metrics:
                logger.debug(
                    f"è¨­å‚™ {name} ({equipment_id}) åœ¨éå»30åˆ†é˜å…§æ²’æœ‰æ–°çš„ç›£æ¸¬æŒ‡æ¨™ã€‚"
                )
                # å¯è€ƒæ…®é•·æ™‚é–“ç„¡æ•¸æ“šå›å ±çš„è™•ç†é‚è¼¯
                return

            for metric_type, data in latest_metrics.items():
                # åªè™•ç† self.equipment_metrics ä¸­ç‚º DICER å®šç¾©çš„æŒ‡æ¨™
                if metric_type in self.equipment_metrics.get(self.DICER, []) and data["value"] is not None:
                    # ä½¿ç”¨å¾è³‡æ–™åº«è¼‰å…¥çš„é–¾å€¼æ•¸æ“šé€²è¡Œåˆ¤æ–·
                    severity = self._determine_severity(
                        metric_type, data["value"]
                    )

                    # åªæœ‰åœ¨åˆ¤æ–·å‡ºé None çš„åš´é‡ç¨‹åº¦æ™‚æ‰åŠ å…¥ anomalies
                    if severity:
                        anomalies.append({
                            "metric": metric_type,
                            "value": data["value"],
                            "unit": data["unit"],
                            "severity": severity,
                            "timestamp": data["timestamp"]
                        })

            if anomalies:
                highest_severity = max(
                    (a["severity"] for a in anomalies),
                    key=self._severity_level,
                    default=self.SEVERITY_WARNING
                )
                anomaly_messages = []
                for anomaly in anomalies:
                    ts_str = (
                        anomaly['timestamp'].strftime('%H:%M:%S')
                        if anomaly.get('timestamp') else 'N/A'
                    )
                    msg = ""
                    # å¾ self.metric_thresholds_data ç²å–æ­£å¸¸å€¼ä»¥ä¾›é¡¯ç¤º
                    normal_val_display = self.metric_thresholds_data.get(
                        anomaly["metric"], {}
                    ).get("normal_value")

                    if anomaly["metric"] == "è½‰é€Ÿ":
                        msg = (
                            f"æŒ‡æ¨™ {anomaly['metric']} å€¼ {anomaly['value']:.0f} RPM "
                            f"(æ­£å¸¸æ‡‰ç‚º {normal_val_display:.0f} RPM å·¦å³)"
                            if normal_val_display is not None else ""
                        ) + (
                            f"ã€‚åµæ¸¬ç‚º {anomaly['severity'].upper()} ç­‰ç´šç•°å¸¸ (æ–¼ {ts_str})"
                        )
                    elif anomaly["metric"] == "è®Šå½¢é‡(mm)":
                        msg = (
                            f"æŒ‡æ¨™ {anomaly['metric']} å€¼ {anomaly['value']:.3f} mm"
                            f"(æ­£å¸¸æ‡‰ç‚º {normal_val_display:.3f} mm ä»¥ä¸‹)"
                            if normal_val_display is not None else ""
                        ) + (
                            f"ã€‚åµæ¸¬ç‚º {anomaly['severity'].upper()} ç­‰ç´šç•°å¸¸ (æ–¼ {ts_str})"
                        )
                    elif anomaly["metric"] == "åˆ€å…·è£‚ç—•":  # æ–°å¢åˆ€å…·è£‚ç—•çš„è¨Šæ¯æ ¼å¼
                        msg = (
                            f"æŒ‡æ¨™ {anomaly['metric']} å€¼ {anomaly['value']:.3f} mm"
                            f"(æ­£å¸¸æ‡‰ç‚º {normal_val_display:.3f} mm ä»¥ä¸‹)"
                            if normal_val_display is not None else ""
                        ) + (
                            f"ã€‚åµæ¸¬ç‚º {anomaly['severity'].upper()} ç­‰ç´šç•°å¸¸ (æ–¼ {ts_str})"
                        )
                    else:
                        msg = (
                            f"æŒ‡æ¨™ {anomaly['metric']} å€¼ {anomaly['value']:.2f} {anomaly['unit'] or ''}ã€‚"
                            f"åµæ¸¬ç‚º {anomaly['severity'].upper()} ç­‰ç´šç•°å¸¸ (æ–¼ {ts_str})"
                        )
                    anomaly_messages.append(msg)

                full_message = (
                    f"è¨­å‚™ {name} ({equipment_id}) ç•°å¸¸æé†’ "
                    f"({self._severity_emoji(highest_severity)} {highest_severity.upper()}):\n"
                    + "\n".join(anomaly_messages)
                )

                for anomaly in anomalies:
                    alert_msg_for_db = (
                        f"{anomaly['metric']} å€¼ {anomaly['value']:.2f} {anomaly['unit'] or ''} "
                        f"(åš´é‡ç¨‹åº¦: {anomaly['severity'].upper()})"
                    )
                    cursor.execute(
                        """
                        INSERT INTO alert_history (equipment_id, alert_type, severity, message, created_at)
                        VALUES (?, ?, ?, ?, GETDATE()); -- created_at è‡ªå‹•å¡«å¯«
                        """,
                        (
                            equipment_id,
                            f"{anomaly['metric']}_alert",
                            anomaly["severity"],
                            alert_msg_for_db
                        )
                    )

                self._update_equipment_status(
                    conn, equipment_id, highest_severity, full_message
                )
                conn.commit()
                self._send_alert_notification(equipment_id, full_message, highest_severity)
                logger.info(
                    f"è¨­å‚™ {name} ({equipment_id}) ç•°å¸¸å·²è¨˜éŒ„åŠé€šçŸ¥ ({highest_severity})ã€‚"
                )
            else:
                cursor.execute(
                    "SELECT status FROM equipment WHERE equipment_id = ?;", (equipment_id,)
                )
                current_status_row = cursor.fetchone()
                if current_status_row and current_status_row[0] not in ['normal', 'offline']:
                    logger.info(
                        f"è¨­å‚™ {name} ({equipment_id}) æŒ‡æ¨™å·²æ¢å¾©æ­£å¸¸ï¼Œ"
                        f"å…ˆå‰ç‹€æ…‹ç‚º {current_status_row[0]}ã€‚"
                    )
                    self._update_equipment_status(conn, equipment_id, "normal", "æŒ‡æ¨™å·²æ¢å¾©æ­£å¸¸")
                    conn.commit()

        except pyodbc.Error as db_err:
            logger.error(
                f"æª¢æŸ¥è¨­å‚™ {name} ({equipment_id}) æŒ‡æ¨™æ™‚ç™¼ç”Ÿè³‡æ–™åº«éŒ¯èª¤: {db_err}"
            )
        except Exception as e:
            logger.error(
                f"æª¢æŸ¥è¨­å‚™ {name} ({equipment_id}) æŒ‡æ¨™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}"
            )

    def _update_equipment_status(
        self, conn, equipment_id, new_status_key, alert_message_for_log="ç‹€æ…‹æ›´æ–°"
    ):
        """è¼”åŠ©å‡½æ•¸ï¼šæ›´æ–°è¨­å‚™ç‹€æ…‹ä¸¦è¨˜éŒ„åˆ° alert_history (å¦‚æœç‹€æ…‹æ”¹è®Š)"""
        status_map = {
            self.SEVERITY_WARNING: "warning",
            self.SEVERITY_CRITICAL: "critical",
            self.SEVERITY_EMERGENCY: "emergency",
            "normal": "normal",
            "offline": "offline",
            "stale_data": "warning"
        }
        db_status = status_map.get(new_status_key, "warning")

        cursor = conn.cursor()
        cursor.execute(
            "SELECT status FROM equipment WHERE equipment_id = ?;", (equipment_id,)
        )
        current_status_row = cursor.fetchone()

        if current_status_row and current_status_row[0] != db_status:
            cursor.execute(
                "UPDATE equipment SET status = ?, last_updated = GETDATE() "
                "WHERE equipment_id = ?;",
                (db_status, equipment_id)
            )
            if new_status_key == "normal" or db_status != current_status_row[0]:
                alert_type = (
                    "status_change" if new_status_key != "normal" else "recovery"
                )
                severity_for_log = (
                    new_status_key if new_status_key != "normal" else "info"
                )
                is_resolved_log = 1 if new_status_key == "normal" else 0
                cursor.execute(
                    """
                    INSERT INTO alert_history
                        (equipment_id, alert_type, severity, message, is_resolved, created_at)
                    VALUES (?, ?, ?, ?, ?, GETDATE());
                    """,
                    (
                        equipment_id,
                        alert_type,
                        severity_for_log,
                        alert_message_for_log,
                        is_resolved_log
                    )
                )
            logger.info(
                f"è¨­å‚™ {equipment_id} ç‹€æ…‹å¾ {current_status_row[0]} æ›´æ–°ç‚º {db_status}ã€‚"
            )
            return True
        return False

    def _check_operation_status(self, conn, equipment_id, name, eq_type):
        """æª¢æŸ¥è¨­å‚™é‹è¡Œç‹€æ…‹ï¼ŒåŒ…æ‹¬é•·æ™‚é–“é‹è¡Œã€ç•°å¸¸åœæ©Ÿç­‰ (å·²åœç”¨)"""
        logger.debug(f"è¨­å‚™ {name} ({equipment_id}) çš„é‹è¡Œç‹€æ…‹ç›£æ§å·²åœç”¨ã€‚")
        return

    def _determine_severity(self, metric_type, value):
        """
        æ ¹æ“šè¼‰å…¥çš„é–¾å€¼æ•¸æ“šï¼Œåˆ¤æ–·æŒ‡æ¨™çš„åš´é‡ç¨‹åº¦ã€‚
        """
        val = float(value)
        thresholds = self.metric_thresholds_data.get(metric_type)

        if not thresholds:
            logger.warning(f"æœªæ‰¾åˆ°æŒ‡æ¨™ '{metric_type}' çš„é–¾å€¼æ•¸æ“šã€‚ç„¡æ³•åˆ¤æ–·åš´é‡ç¨‹åº¦ã€‚")
            return None

        # å„ªå…ˆåˆ¤æ–·é‡åº¦ç•°å¸¸
        emergency_thresh = thresholds.get("emergency")
        if emergency_thresh:
            e_min = emergency_thresh.get("min")
            e_max = emergency_thresh.get("max")
            e_op = emergency_thresh.get("op")

            if e_op == '>':
                if e_min is not None and val > e_min:
                    return self.SEVERITY_EMERGENCY
            elif e_op == '<':
                if e_max is not None and val < e_max:
                    return self.SEVERITY_EMERGENCY
            # å¦‚æœæ²’æœ‰æ“ä½œç¬¦ï¼Œå‰‡é è¨­ç‚ºå€é–“ [min, max]
            elif e_min is not None and e_max is not None and e_min <= val <= e_max:
                return self.SEVERITY_EMERGENCY

        # åˆ¤æ–·ä¸­åº¦ç•°å¸¸ (è‡¨ç•Œ)
        critical_thresh = thresholds.get("critical")
        if critical_thresh:
            c_min = critical_thresh.get("min")
            c_max = critical_thresh.get("max")
            # å€é–“åˆ¤æ–· (min, max]
            if c_min is not None and c_max is not None and c_min < val <= c_max:
                return self.SEVERITY_CRITICAL

        # åˆ¤æ–·è¼•åº¦ç•°å¸¸ (è­¦å‘Š)
        warning_thresh = thresholds.get("warning")
        if warning_thresh:
            w_min = warning_thresh.get("min")
            w_max = warning_thresh.get("max")
            # å€é–“åˆ¤æ–· (min, max]
            if w_min is not None and w_max is not None and w_min < val <= w_max:
                return self.SEVERITY_WARNING

        return None  # å¦‚æœä¸åœ¨ä»»ä½•ç•°å¸¸å€é–“å…§ï¼Œå‰‡è¦–ç‚ºæ­£å¸¸

    def _severity_level(self, severity):
        levels = {
            self.SEVERITY_WARNING: 1,
            self.SEVERITY_CRITICAL: 2,
            self.SEVERITY_EMERGENCY: 3,
            "info": 0,
            "normal_recovery": 0
        }
        return levels.get(severity, 0)

    def _severity_emoji(self, severity):
        emojis = {
            self.SEVERITY_WARNING: "âš ï¸",
            self.SEVERITY_CRITICAL: "ğŸ”´",
            self.SEVERITY_EMERGENCY: "ğŸš¨",
            "info": "â„¹ï¸",
            "normal_recovery": "âœ…"
        }
        return emojis.get(severity, "âš ï¸")

    def _get_equipment_data(self, conn_unused, equipment_id):
        """å¾è³‡æ–™åº«ç²å–æŒ‡å®šè¨­å‚™çš„åç¨±ã€é¡å‹å’Œä½ç½®è³‡è¨Š"""
        try:
            with self.db._get_connection() as new_conn:
                cursor = new_conn.cursor()
                cursor.execute(
                    "SELECT name, eq_type, location FROM equipment WHERE equipment_id = ?;",
                    (equipment_id,),
                )
                result = cursor.fetchone()
                if result:
                    return {
                        "name": result[0], "type": result[1],
                        "type_name": self.equipment_type_names.get(result[1], result[1]),
                        "location": result[2]
                    }
        except pyodbc.Error as db_err:
            logger.error(
                f"å¾ _get_equipment_data ç²å–è¨­å‚™ {equipment_id} è³‡æ–™å¤±æ•—: {db_err}"
            )
        return {
            "name": "æœªçŸ¥", "type": "æœªçŸ¥",
            "type_name": "æœªçŸ¥è¨­å‚™", "location": "æœªçŸ¥"
        }

    def _generate_ai_recommendation(self, anomalies, equipment_data):
        """ç”¢ç”Ÿ AI å¢å¼·çš„ç•°å¸¸æè¿°å’Œå»ºè­°ï¼ˆä½¿ç”¨ç¾æœ‰çš„ OpenAI æœå‹™ï¼‰"""
        try:
            from src.main import OpenAIService

            context_parts = []
            for anomaly in anomalies:
                ts_str = (
                    anomaly['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
                    if anomaly.get('timestamp') else 'N/A'
                )
                value_str = f"{anomaly['value']:.2f}" if anomaly['value'] is not None else "N/A"

                normal_val_display = self.metric_thresholds_data.get(
                    anomaly["metric"], {}
                ).get("normal_value")

                if anomaly["metric"] == "è½‰é€Ÿ":
                    metric_detail = (f"è½‰é€Ÿ: {int(anomaly['value'])} RPM "
                                     f"(æ­£å¸¸ç´„ {int(normal_val_display)} RPM)"
                                     if normal_val_display is not None else "RPM")
                elif anomaly["metric"] in ["è®Šå½¢é‡(mm)", "åˆ€å…·è£‚ç—•"]:  # çµ±ä¸€è™•ç†é€™å…©ç¨®
                    metric_detail = (f"{anomaly['metric']}: {anomaly['value']:.3f} mm "
                                     f"(æ­£å¸¸ç´„ {normal_val_display:.3f} mm ä»¥ä¸‹)"
                                     if normal_val_display is not None else "mm")
                else:
                    metric_detail = (
                        f"æŒ‡æ¨™ '{anomaly['metric']}': ç›®å‰å€¼ {value_str} "
                        f"(å–®ä½: {anomaly['unit'] or ''})"
                    )

                context_parts.append(f"- {metric_detail}, è¨˜éŒ„æ™‚é–“: {ts_str}, ç•°å¸¸ç­‰ç´š: {anomaly['severity'].upper()}")
            context = "åµæ¸¬åˆ°çš„ç•°å¸¸ç‹€æ³:\n" + "\n".join(context_parts)

            prompt = (
                "ä½œç‚ºä¸€å€‹åŠå°é«”è¨­å‚™ç¶­è­·å°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹è¨­å‚™çš„ç•°å¸¸ç‹€æ³ä¸¦æä¾›å…·é«”çš„åˆæ­¥æ’æŸ¥å»ºè­°å’Œå¯èƒ½çš„è§£æ±ºæ–¹æ¡ˆã€‚\n"
                f"è¨­å‚™è³‡æ–™ï¼šåç¨± {equipment_data.get('name')}, "
                f"å‹è™Ÿ {equipment_data.get('type_name')}, "
                f"ä½ç½® {equipment_data.get('location')}\n"
                f"ç•°å¸¸è©³æƒ…ï¼š\n{context}\n"
                "è«‹ä»¥ç°¡æ½”ã€æ¢åˆ—å¼çš„æ–¹å¼æä¾›å»ºè­°ï¼Œé‡é»æ”¾åœ¨æ“ä½œå“¡æˆ–åˆç´šç¶­è­·äººå“¡å¯ä»¥åŸ·è¡Œçš„æª¢æŸ¥æ­¥é©Ÿã€‚"
            )

            system_ai_user_id = "SYSTEM_AI_HELPER_EQUIPMENT"
            db.set_user_preference(system_ai_user_id, language="zh-Hant")

            service = OpenAIService(message=prompt, user_id=system_ai_user_id)
            response = service.get_response()
            return response
        except ImportError as imp_err:
            logger.error(f"ç„¡æ³•å°å…¥ OpenAIService: {imp_err}")
            return "ç„¡æ³•ç²å– AI å»ºè­° (æ¨¡çµ„å°å…¥éŒ¯èª¤)ã€‚"
        except Exception as e:
            logger.exception(f"ç”¢ç”Ÿ AI å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return "ç„¡æ³•ç²å– AI å»ºè­° (ç³»çµ±éŒ¯èª¤)ã€‚"

    def _send_alert_notification(self, equipment_id, message, severity):
        """ç™¼é€é€šçŸ¥çµ¦è¨‚é–±è©²è¨­å‚™çš„ä½¿ç”¨è€…åŠç›¸é—œè² è²¬äºº"""
        try:
            from src.linebot_connect import send_notification

            user_ids_to_notify = set()

            with self.db._get_connection() as conn:
                cursor = conn.cursor()
                level_filter_tuple = ()
                if severity == self.SEVERITY_EMERGENCY:
                    level_filter_tuple = ('all', 'critical', 'emergency')
                elif severity == self.SEVERITY_CRITICAL:
                    level_filter_tuple = ('all', 'critical')
                elif severity == self.SEVERITY_WARNING:
                    level_filter_tuple = ('all',)
                else:
                    level_filter_tuple = ('all',)

                if level_filter_tuple:
                    placeholders = ', '.join(['?'] * len(level_filter_tuple))
                    sql_subscriptions = (
                        f"SELECT user_id FROM user_equipment_subscriptions "
                        f"WHERE equipment_id = ? AND notification_level IN ({placeholders});"
                    )
                    params = [equipment_id] + list(level_filter_tuple)
                    cursor.execute(sql_subscriptions, params)
                    for row in cursor.fetchall():
                        user_ids_to_notify.add(row[0])

                cursor.execute(
                    "SELECT eq_type FROM equipment WHERE equipment_id = ?;", (equipment_id,)
                )
                equipment_info = cursor.fetchone()
                if equipment_info:
                    equipment_type = equipment_info[0]
                    cursor.execute(
                        "SELECT user_id FROM user_preferences "
                        "WHERE responsible_area = ? OR is_admin = 1;",
                        (equipment_type,)
                    )
                    for row in cursor.fetchall():
                        user_ids_to_notify.add(row[0])

            if not user_ids_to_notify:
                logger.warning(
                    f"è¨­å‚™ {equipment_id} ç™¼ç”Ÿè­¦å ±ï¼Œä½†æ‰¾ä¸åˆ°ä»»ä½•ç¬¦åˆæ¢ä»¶çš„é€šçŸ¥å°è±¡ã€‚"
                )
                return  # Added return here if no users to notify

            final_message = (
                f"{self._severity_emoji(severity)} "
                f"è¨­å‚™è­¦å ± ({equipment_id}):\n{message}"
            )

            for user_id_val in user_ids_to_notify:
                if send_notification(user_id_val, final_message):
                    logger.info(
                        f"è­¦å ±é€šçŸ¥å·²ç™¼é€çµ¦ä½¿ç”¨è€…: {user_id_val} é‡å°è¨­å‚™ {equipment_id}"
                    )
                else:
                    logger.error(f"ç™¼é€è­¦å ±é€šçŸ¥çµ¦ä½¿ç”¨è€…: {user_id_val} å¤±æ•—")

        except pyodbc.Error as db_err:
            logger.exception(
                f"ç™¼é€è¨­å‚™ {equipment_id} çš„é€šçŸ¥æ™‚ç™¼ç”Ÿè³‡æ–™åº«éŒ¯èª¤: {db_err}"
            )
        except ImportError:  # send_notification å°å…¥å¤±æ•—
            logger.error("ç„¡æ³•å°å…¥ send_notification å‡½æ•¸ã€‚è­¦å ±ç„¡æ³•ç™¼é€ã€‚")
        except Exception as e:  # Renamed 'e' from previous 'e' in _check_equipment_metrics
            logger.exception(
                f"ç™¼é€è¨­å‚™ {equipment_id} çš„é€šçŸ¥æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e}"
            )
